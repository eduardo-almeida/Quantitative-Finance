1. Dados de escalonamento e regressão KNN
Neste capítulo, usaremos vizinhos k-mais próximos e redes neurais para prever valores de estoque futuros. Ambos os métodos normalmente funcionam melhor com dados padronizados, que aprenderemos como fazer usando Python e sklearn.

2. Remova recursos sem importância
Antes de prosseguirmos, vamos revisar. Vimos as importâncias dos recursos de nossos modelos baseados em árvore. Esses dias da semana mostrados não são importantes.

3. Seleção de recursos: remova os dias da semana
Vamos remover esses recursos sem importância. Isso faz parte da "seleção de recursos", que é uma etapa importante no aprendizado de máquina. Lembre-se de que criamos os recursos do dia da semana por último, portanto, podemos remover as quatro variáveis ​​do dia da semana indexando até as últimas quatro colunas.

4. Remova os dias da semana
Nossas variáveis ​​de recursos são pandas DataFrames, então usaremos dot-iloc para indexar os recursos e remover os dias da semana.

5. Introdução ao KNN
Agora vamos ver como os k-vizinhos mais próximos, ou KNN, funcionam. Digamos que temos dados com recursos bidimensionais que se parecem com isso. Os valores do alvo são mostrados em cada ponto.

6. Previsões KNN
Se tivermos um novo ponto, mostrado em azul, qual é o seu valor alvo? KNN pega os k-pontos mais próximos a este novo ponto e calcula a média de seus valores alvo para obter nossa previsão.

7. Previsões KNN
Precisamos escolher o número de vizinhos como um hiperparâmetro, que diremos aqui é 2. Pegamos a média dos 2 pontos mais próximos e temos nossa previsão de 5.

8. Equação de distância de Minowski
Foi fácil ver quais pontos estão mais próximos no gráfico anterior. Mas isso não funcionará para cálculos - precisamos usar matemática. KNN usa a distância de Minowski para medir a distância entre os pontos. É o mesmo que distância euclidiana, ou distância em linha reta, quando p = 2.

9. Recursos grandes versus pequenos
Se o intervalo de um recurso for pequeno e o de outro for grande, o recurso maior terá mais peso do que o menor nos cálculos de distância. Isso pode afetar negativamente o desempenho do nosso modelo. Normalmente, é melhor normalizar os dados para que os recursos tenham intervalos semelhantes. Por exemplo, o intervalo dos valores y mostrados aqui é muito maior do que o intervalo do valor x, portanto, y supera x nos cálculos de distância. O gráfico à direita tem intervalos iguais dos eixos xey para destacar a diferença de magnitude.

10. Opções de escala
Entre as opções de escala de dados estão escala mín-máx, padronização, escala de desvio absoluto mediana e mediana e mapeamento para funções como tangente sigmóide ou hiperbólica. Nesse caso, usaremos a padronização, pois é fácil de usar e funciona bem.

11. Efeitos de padronização em KNN
Nossos recursos têm faixas semelhantes após a padronização. Isso significa que o KNN não será inclinado para grandes recursos em cálculos de distância. Às vezes isso é útil, outras vezes não. Podemos querer enviesar o modelo KNN para características de alta importância, encontradas em nossa floresta aleatória.

12. scaler do sklearn
Para padronizar nossos recursos, podemos usar a classe scaler de sklearn-dot-preprocessing. Primeiro criamos uma instância da classe e, em seguida, usamos o método dot-fit_transform em nossos train_features. Isso ajusta o escalonador aos dados de treinamento e os transforma ao mesmo tempo. Em seguida, usamos a transformação de ponto em test_features para transformar os dados de teste.

13. Padronização
A padronização subtrai a média de todos os pontos de dados e, em seguida, divide pelo desvio padrão. Isso define a média em 0 e o desvio padrão em 1. Isso funciona melhor com distribuições gaussianas ou normais. Aqui vemos o efeito da padronização da média móvel do RSI de 14 dias.

14. Fazendo subtramas
Para fazer o gráfico anterior, criamos subparcelas com 2 linhas e 1 coluna. Isso retorna uma figura e uma lista de eixos. Nossos recursos são um DataFrame pandas, então usamos ponto-iloc para obter todas as linhas, e a 3ª coluna que é a média móvel RSI de 14 dias. Os recursos escalados são uma matriz numpy, portanto, podemos indexar com colchetes e, em seguida, plotar usando o segundo eixo na lista de eixos.

15. Dimensione os dados e use KNN!
Ok, vamos dimensionar nossos recursos e ver como funciona o KNN.